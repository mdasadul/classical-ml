{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classification\n",
    "\n",
    "The dataset was obtained from https://www.kaggle.com/nltkdata/movie-review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5574 entries, 0 to 5573\n",
      "Data columns (total 2 columns):\n",
      "tag     5574 non-null object\n",
      "text    5574 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# read data and parse it\n",
    "data = pd.read_csv('../datasets/sms_spam.csv', names=['tag', 'text'])\n",
    "data.text = [str(doc) for doc in data['text']]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data 70 % train, 30 % test\n",
    "train_df = data.iloc[:3000, :]\n",
    "test_df = data.iloc[3001:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesText:\n",
    "    \n",
    "    def __init__(self, train_df):\n",
    "        \"\"\"\n",
    "        train_df (pandas.DataFrame) : Training dataset\n",
    "        train_df must have a column called 'tag' representing the output class,\n",
    "            and a column called 'text'\n",
    "        \"\"\"\n",
    "        self.train_df = train_df\n",
    "        # pre-processing to remove punctuations\n",
    "        self.train_df['text'] = [\n",
    "            re.sub('\\d|\\\"|\\'|!|\\)|\\(|\\.|,|\\\\b', '', doc).split() \n",
    "            for doc in train_df.text.values]\n",
    "        self.tags = list(set(train_df.tag.values))\n",
    "        self.total_vocabulary_size = len(self.get_vocabulary(self.train_df))\n",
    "        self.tag_vocabulary_counts = {tag : Counter(self.get_vocabulary(\n",
    "            self.train_df.loc[self.train_df['tag'] == tag])) for tag in self.tags}\n",
    "    \n",
    "    def get_vocabulary(self, df):\n",
    "        vocabulary = []\n",
    "        for doc_list in df.text.values:\n",
    "            for word in doc_list:\n",
    "                vocabulary.append(word)\n",
    "        return vocabulary\n",
    "    \n",
    "    def prob_tag(self, tag):\n",
    "        return len(self.train_df.loc[self.train_df['tag'] == tag])/len(self.train_df)\n",
    "\n",
    "    def prob_doc_given_tag(self, doc, tag, alpha):\n",
    "        prob_words = np.array([self.prob_word_given_tag(word, tag, alpha) \n",
    "                               for word in doc.split()])\n",
    "        return np.prod(prob_words) * self.prob_tag(tag)\n",
    "\n",
    "    def prob_word_given_tag(self, word, tag, alpha):\n",
    "        word_count = self.tag_vocabulary_counts[tag][word]\n",
    "        return (word_count + alpha)/(len(self.tag_vocabulary_counts) + alpha * \n",
    "                                          self.total_vocabulary_size)\n",
    "\n",
    "    def predict_tag(self, doc, alpha):\n",
    "        prob_tags = np.array([self.prob_doc_given_tag(doc, tag, alpha) for tag in self.tags])\n",
    "        return self.tags[np.argmax(prob_tags)]\n",
    "    \n",
    "    def predict_batch(self, docs, print_progress = False, alpha=1):\n",
    "        predict_tags = []\n",
    "        i = 0\n",
    "        for doc in docs:\n",
    "            predict_tags.append(self.predict_tag(doc, alpha))\n",
    "            if print_progress and i % len(docs)//10 == 0:\n",
    "                print(\"Predicted {} of {} documents\".format(i * len(docs)//10, len(docs)))\n",
    "            i += 1\n",
    "        if print_progress:\n",
    "            print(\"Predicted all documents\\n\")\n",
    "        return predict_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_alpha(train_data):\n",
    "    alpha_values = [x/100 for x in range(500, 600, 5)]\n",
    "    accuracies = np.zeros([len(alpha_values), len(train_data.fold_id.values)])\n",
    "    for fold in range(len(train_data.fold_id.values)):\n",
    "        test = train_data.loc[train_data['fold_id'] == fold]\n",
    "        train = train_data.loc[train_data['fold_id'] != fold]\n",
    "        nbt = NaiveBayesText(train)\n",
    "        if len(test['tag']) == 0:\n",
    "            continue\n",
    "        i = 0\n",
    "        for a in alpha_values:\n",
    "            y_hat = nbt.predict_batch(test['text'], alpha=a)\n",
    "            accuracy = calculate_accuracy(y_hat, test['tag'])\n",
    "            accuracies[i][fold] = accuracy\n",
    "            i += 1\n",
    "    alpha_accuracies = accuracies.mean(axis=1)\n",
    "    for j in range(len(alpha_values)):\n",
    "        print(\"validation accuracy for alpha = {} is {}\"\n",
    "              .format(alpha_values[j], alpha_accuracies[j]))\n",
    "    return alpha_values[np.argmax(alpha_accuracies)]\n",
    "\n",
    "def calculate_accuracy(y_hat, y):\n",
    "    return sum(1 for a, b in zip(y_hat,y) if a == b) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranaymethuku/.local/lib/python3.5/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 0 of 2573 documents\n",
      "Predicted 257 of 2573 documents\n",
      "Predicted 514 of 2573 documents\n",
      "Predicted 771 of 2573 documents\n",
      "Predicted 1029 of 2573 documents\n",
      "Predicted 1286 of 2573 documents\n",
      "Predicted 1543 of 2573 documents\n",
      "Predicted 1801 of 2573 documents\n",
      "Predicted 2058 of 2573 documents\n",
      "Predicted 2315 of 2573 documents\n",
      "Predicted all documents\n",
      "\n",
      "Test set accuracy: 90.983%\n"
     ]
    }
   ],
   "source": [
    "# best_alpha = get_best_alpha(train_df)\n",
    "# Use the best parameter\n",
    "nbt = NaiveBayesText(train_df)\n",
    "y_hat = nbt.predict_batch(test_df['text'], print_progress=True)\n",
    "test_acc = calculate_accuracy(test_df['tag'], y_hat)\n",
    "print(\"Test set accuracy: {:1.3f}%\".format(test_acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
