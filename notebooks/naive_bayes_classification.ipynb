{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classification\n",
    "\n",
    "The dataset was obtained from https://www.kaggle.com/nltkdata/movie-review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data and parse it\n",
    "data = pd.read_csv('../datasets/movie_reviews_smaller.csv')\n",
    "data = data[['fold_id', 'text', 'tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data 70 % train, 30 % test\n",
    "train_df = data.loc[data['fold_id'] < 3]\n",
    "test_df = data.loc[data['fold_id'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_alpha(train_data):\n",
    "    alpha_values = [x/100 for x in range(500, 600, 5)]\n",
    "    accuracies = np.zeros([len(alpha_values), len(train_data.fold_id.values)])\n",
    "    for fold in range(len(train_data.fold_id.values)):\n",
    "        test = train_data.loc[train_data['fold_id'] == fold]\n",
    "        train = train_data.loc[train_data['fold_id'] != fold]\n",
    "        nbt = NaiveBayesText(train)\n",
    "        if len(test['tag']) == 0:\n",
    "            continue\n",
    "        i = 0\n",
    "        for a in alpha_values:\n",
    "            y_hat = nbt.predict_batch(test['text'], alpha=a)\n",
    "            accuracy = calculate_accuracy(y_hat, test['tag'])\n",
    "            print(\"validation accuracy for fold = {}, alpha = {} is {:1.3f}\"\n",
    "                  .format(fold, a, accuracy))\n",
    "            accuracies[i][fold] = accuracy\n",
    "            i += 1\n",
    "    return alpha_values[np.argmax(accuracies.mean(axis=1))]\n",
    "\n",
    "def calculate_accuracy(y_hat, y):\n",
    "    return sum(1 for a, b in zip(y_hat,y) if a == b) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesText:\n",
    "    \n",
    "    def __init__(self, train_df):\n",
    "        \"\"\"\n",
    "        train_df (pandas.DataFrame) : Training dataset\n",
    "        train_df must have a column called 'tag' representing the output class,\n",
    "            and a column called 'text'\n",
    "        \"\"\"\n",
    "        self.train_df = train_df\n",
    "        # change documents to a bag of words representation\n",
    "        if type(self.train_df.text.values[0]) == 'str':\n",
    "            self.clean_documents()\n",
    "        self.tags = list(set(train_df.tag.values))\n",
    "        self.tag_vocabulary_counts = {tag : Counter(self.get_vocabulary(\n",
    "            self.train_df.loc[self.train_df['tag'] == tag])) for tag in self.tags}\n",
    "        self.total_vocabulary_size = len(self.get_vocabulary(self.train_df))\n",
    "        \n",
    "    def clean_documents(self):\n",
    "        waste = '\\d|\\\"|\\'|!|\\)|\\(|\\.|,|' + '\\\\b(' + \\\n",
    "            '|'.join(stopwords.words('english')) + ')\\\\W'\n",
    "        self.train_df.loc[:, self.train_df.columns == 'text'] = self.train_df.text.apply(\n",
    "            lambda doc : self.clean_document(doc, waste))\n",
    "\n",
    "    def clean_document(self, doc, waste):\n",
    "        \"\"\" Removes useless filler words/punctuations from text \"\"\"\n",
    "        return re.sub(waste, '', doc).split()\n",
    "    \n",
    "    def get_vocabulary(self, df):\n",
    "        vocabulary = []\n",
    "        for doc_list in df.text.values:\n",
    "            for word in doc_list:\n",
    "                vocabulary.append(word)\n",
    "        return vocabulary\n",
    "    \n",
    "    def prob_tag(self, tag):\n",
    "        return len(self.train_df.loc[self.train_df['tag'] == tag])/len(self.train_df)\n",
    "\n",
    "    def prob_doc_given_tag(self, doc, tag, alpha):\n",
    "        prob_words = np.array([self.prob_word_given_tag(word, tag, alpha) \n",
    "                               for word in doc.split()])\n",
    "        return np.prod(prob_words) * self.prob_tag(tag)\n",
    "\n",
    "    def prob_word_given_tag(self, word, tag, alpha):\n",
    "        word_count = self.tag_vocabulary_counts[tag][word]\n",
    "        return (word_count + alpha)/(len(self.tag_vocabulary_counts) + alpha * \n",
    "                                          self.total_vocabulary_size)\n",
    "\n",
    "    def predict_tag(self, doc, alpha):\n",
    "        prob_tags = np.array([self.prob_doc_given_tag(doc, tag, alpha) for tag in self.tags])\n",
    "        return self.tags[np.argmax(prob_tags)]\n",
    "    \n",
    "    def predict_batch(self, docs, print_progress = False, alpha=1):\n",
    "        predict_tags = []\n",
    "        i = 0\n",
    "        for doc in docs:\n",
    "            predict_tags.append(self.predict_tag(doc, alpha))\n",
    "            if print_progress and i % 2000 == 0:\n",
    "                print(\"Predicted {} of {} documents\".format(i, len(docs)))\n",
    "            i += 1\n",
    "        if print_progress:\n",
    "            print(\"Predicted all documents\\n\")\n",
    "        return predict_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy for fold = 0, alpha = 5.0 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.05 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.1 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.15 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.2 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.25 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.3 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.35 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.4 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.45 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.5 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.55 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.6 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.65 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.7 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.75 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.8 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.85 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.9 is 0.530\n",
      "validation accuracy for fold = 0, alpha = 5.95 is 0.530\n",
      "validation accuracy for fold = 1, alpha = 5.0 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.05 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.1 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.15 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.2 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.25 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.3 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.35 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.4 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.45 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.5 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.55 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.6 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.65 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.7 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.75 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.8 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.85 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.9 is 0.455\n",
      "validation accuracy for fold = 1, alpha = 5.95 is 0.455\n",
      "validation accuracy for fold = 2, alpha = 5.0 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.05 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.1 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.15 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.2 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.25 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.3 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.35 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.4 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.45 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.5 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.55 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.6 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.65 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.7 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.75 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.8 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.85 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.9 is 0.555\n",
      "validation accuracy for fold = 2, alpha = 5.95 is 0.555\n",
      "Predicted 0 of 202 documents\n",
      "Predicted all documents\n",
      "\n",
      "Test set accuracy: 56.931%\n"
     ]
    }
   ],
   "source": [
    "best_alpha = get_best_alpha(train_df)\n",
    "# Use the best parameter\n",
    "nbt = NaiveBayesText(train_df)\n",
    "y_hat = nbt.predict_batch(test_df['text'], print_progress=True, alpha=best_alpha)\n",
    "test_acc = calculate_accuracy(test_df['tag'], y_hat)\n",
    "print(\"Test set accuracy: {:1.3f}%\".format(test_acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
